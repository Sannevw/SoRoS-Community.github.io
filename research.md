[[Home](index.html)]
### Recent Papers

#### Yuan Gao's publication list

> You can also find the more detailed list here: https://gaoyuankidult.github.io/publications/

Yuan Gao, Fangkai Yang, Martin Frisk, Daniel Hernandez, Christopher Peters and Ginevra Castellano, Social Behavior Learning with Realistic Reward Shaping, arXiv 2018. [[Paper]](https://arxiv.org/abs/1810.06979) [[GitHub]](https://github.com/usr-lab/PepperSocial)

Yuan Gao, Sebastian Wallk√∂tter, Mohammad Obaid, Ginevra Castellano, Human-Robot Proxemics using Recurrent Neural Networks, IEEE International Conference on Robot and Human Interactive Communication (RO-MAN 2018), 2018. [[Paper]](https://usr-lab.github.io/publications/papers/investigate-deep-learning-proximics.pdf)

Yuan Gao, Wolmet Barendregt, Mohammad Obaid, Ginevra Castellan, When robot personalisation does not help: Insights from a robot-supported learning study, IEEE International Conference on Robot and Human Interactive Communication (RO-MAN 2018), 2018. [[Paper]](https://usr-lab.github.io/publications/papers/when-robot-does-not-help.pdf)

Chengjie Li, Theofronia Androulakaki, Yuan Gao, Fangkai Yang, Himangshu Saikia, Christopher Peters and Gabriel Skantze, Effects of Posture and Embodiment on Social Distance in Human-Agent Interaction in Mixed Reality, 18th ACM International Conference on Intelligent Virtual Agents, 2018.


#### Dimosthenis Kontogiorgos' recent publication list

Dimosthenis Kontogiorgos, Elena Sibirtseva, Andre Pereira, Gabriel Skantze and Joakim Gustafson. Multimodal Reference Resolution in Collaborative Assembly Tasks. Workshop on Multimodal Analyses enabling Artificial Agents in Human-Machine Interaction. Boulder. 2018.

Elena Sibirtseva, Dimosthenis Kontogiorgos, Olov Nykvist, Hakan Karaoguz, Iolanda Leite, Joakim Gustafson, Danica Kragic. A Comparison of Visualisation Methods for Disambiguating Verbal Requests in Human-Robot Interaction. ROMAN. NanJing. 2018.

Dimosthenis Kontogiorgos, Vanya Avramova, Simon Alexandersson, Patrik Jonell, Catharine Oertel, Jonas Beskow, Gabriel Skantze and Joakim Gustafson. A Multimodal Corpus for Mutual Gaze and Joint Attention in Multiparty Situated Interaction. LREC. Miyazaki. 2018.

Patrik Jonell, Mattias Bystedt, Per Fallgren, Dimosthenis Kontogiorgos, Jose Lopes, Zofia Malisz, Samuel Mascarenhas, Catharine Oertel, Eran Raveh and Todd Shore. FARMI: A Framework for Recording Multi-Modal Interactions. LREC. Miyazaki. 2018.

Patrik Jonell, Catharine Oertel, Dimosthenis Kontogiorgos, Jonas Beskow and Joakim Gustafson. Crowdsourced Multimodal Corpora Collection Tool. LREC. Miyazaki. 2018.

Dimosthenis Kontogiorgos. Multimodal language grounding for improved human-robot collaboration. ICMI. Glasgow. 2017.

Patrik Jonell, Catharine Oertel, Dimosthenis Kontogiorgos, Jonas Beskow and Joakim Gustafson. Crowdpowered design of virtual attentive listeners. Intelligent Virtual Agents (IVA). Stockholm. 2017.

Catharine Oertel, Patrik Jonell, Dimosthenis Kontogiorgos, Joseph Mendelson, Jonas Beskow and Joakim Gustafson. Crowdsourced design of artificial attentive listeners. Interspeech. Stockholm. 2017.
