[[Home](index.html)]
### Recent Papers

#### Yuan Gao's publication list

> You can also find the more detailed list here: https://gaoyuankidult.github.io/publications/

Yuan Gao, Fangkai Yang, Martin Frisk, Daniel Hernandez, Christopher Peters and Ginevra Castellano, Social Behavior Learning with Realistic Reward Shaping, arXiv 2018. [[Paper]](https://arxiv.org/abs/1810.06979) [[GitHub]](https://github.com/usr-lab/PepperSocial)

Yuan Gao, Sebastian Wallkötter, Mohammad Obaid, Ginevra Castellano, Human-Robot Proxemics using Recurrent Neural Networks, IEEE International Conference on Robot and Human Interactive Communication (RO-MAN 2018), 2018. [[Paper]](https://usr-lab.github.io/publications/papers/investigate-deep-learning-proximics.pdf)

Yuan Gao, Wolmet Barendregt, Mohammad Obaid, Ginevra Castellan, When robot personalisation does not help: Insights from a robot-supported learning study, IEEE International Conference on Robot and Human Interactive Communication (RO-MAN 2018), 2018. [[Paper]](https://usr-lab.github.io/publications/papers/when-robot-does-not-help.pdf)

Chengjie Li, Theofronia Androulakaki, Yuan Gao, Fangkai Yang, Himangshu Saikia, Christopher Peters and Gabriel Skantze, Effects of Posture and Embodiment on Social Distance in Human-Agent Interaction in Mixed Reality, 18th ACM International Conference on Intelligent Virtual Agents, 2018.


#### Dimosthenis Kontogiorgos' recent publication list

Dimosthenis Kontogiorgos, Elena Sibirtseva, Andre Pereira, Gabriel Skantze and Joakim Gustafson. Multimodal Reference Resolution in Collaborative Assembly Tasks. Workshop on Multimodal Analyses enabling Artificial Agents in Human-Machine Interaction. Boulder. 2018.

Elena Sibirtseva, Dimosthenis Kontogiorgos, Olov Nykvist, Hakan Karaoguz, Iolanda Leite, Joakim Gustafson, Danica Kragic. A Comparison of Visualisation Methods for Disambiguating Verbal Requests in Human-Robot Interaction. ROMAN. NanJing. 2018.

Dimosthenis Kontogiorgos, Vanya Avramova, Simon Alexandersson, Patrik Jonell, Catharine Oertel, Jonas Beskow, Gabriel Skantze and Joakim Gustafson. A Multimodal Corpus for Mutual Gaze and Joint Attention in Multiparty Situated Interaction. LREC. Miyazaki. 2018.

Patrik Jonell, Mattias Bystedt, Per Fallgren, Dimosthenis Kontogiorgos, Jose Lopes, Zofia Malisz, Samuel Mascarenhas, Catharine Oertel, Eran Raveh and Todd Shore. FARMI: A Framework for Recording Multi-Modal Interactions. LREC. Miyazaki. 2018.

Patrik Jonell, Catharine Oertel, Dimosthenis Kontogiorgos, Jonas Beskow and Joakim Gustafson. Crowdsourced Multimodal Corpora Collection Tool. LREC. Miyazaki. 2018.

Dimosthenis Kontogiorgos. Multimodal language grounding for improved human-robot collaboration. ICMI. Glasgow. 2017.

Patrik Jonell, Catharine Oertel, Dimosthenis Kontogiorgos, Jonas Beskow and Joakim Gustafson. Crowdpowered design of virtual attentive listeners. Intelligent Virtual Agents (IVA). Stockholm. 2017.

Catharine Oertel, Patrik Jonell, Dimosthenis Kontogiorgos, Joseph Mendelson, Jonas Beskow and Joakim Gustafson. Crowdsourced design of artificial attentive listeners. Interspeech. Stockholm. 2017.

#### Taras Kucherenko's publication list

> You can also find the more detailed list [here](https://svito-zar.github.io/publications/)

Pieter Wolfert, Taras Kucherenko, Hedvig Kjellström, Tony Belpaeme. Should Beat Gestures Be Learned Or Designed? A Benchmarking User Study. ICDL-EPIROB 2019 Workshop on Naturalistic Non-Verbal and Affective Human-Robot Interactions. Oslo. 2019.

Patrik Jonell, Taras Kucherenko, Erik Ekstedt, Jonas Beskow. Learning Non-verbal Behavior for a Social Robot from YouTube Videos. ICDL-EPIROB 2019 Workshop on Naturalistic Non-Verbal and Affective Human-Robot Interactions. Oslo. 2019.

Taras Kucherenko, Dai Hasegawa, Gustav Eje Henter, Naoshi Kaneko, and Hedvig Kjellström. Analyzing input and output representations for speech-driven gesture generation. International Conference on Intelligent Virtual Agents (IVA ‘19). Paris. 2019.

Taras Kucherenko, Dai Hasegawa, Naoshi Kaneko, Gustav Eje Henter, and Hedvig Kjellström. On the importance of representations for speech-driven gesture generation. 18th International Conference on Autonomous Agents and Multiagent Systems (AAMAS ‘19), Extended Abstract. Montreal. 2019.

Taras Kucherenko. Data driven non-verbal behavior generation for humanoid robots. International Conference on Multimodal Interaction (ICMI ‘18), Doctoral Consortium. Boulder. 2018.
